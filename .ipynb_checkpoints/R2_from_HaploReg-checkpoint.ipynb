{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# The tricky part for me is to query haploreg database thorugh their website.\n",
    "# Inspecct the element of the website to find out names of each variable\n",
    "# Recommand using Chrome, go to developer mode, refresh the website under Network tab\n",
    "\n",
    "# Parameters needed to send to haploreg website, and some explaination\n",
    "# input_snps (query): input SNPs in a string, each SNP is separated by ','\n",
    "#        SNP number per query is set to be 1000, otherwise it takes too long and haploreg may refuse to do it.\n",
    "#        15000 SNPs did not work for test run.\n",
    "# gwas_id: the dropdown list to choose GWAS study, when no file or query SNP(s) is provided\n",
    "# r2_threshold (ldThresh): r^2 threshold, default is 0.2 in this code\n",
    "# ldPop: 1000G Phase 1 population for LD calculation\n",
    "# epi: Source for epigenomes\n",
    "# cons: Mammalian conservation algorithm. 'siphy'=SiPhy-omega, 'gerp'=GERP, or 'both'\n",
    "# genetypes: Show position relative to\n",
    "# output: set output result type to 'text' for python code to process\n",
    "def query_haploreg(input_snps,\n",
    "                   r2_threshold=0.8,\n",
    "                   ldPop='EUR',\n",
    "                   epi='vanilla',\n",
    "                   cons='siphy',\n",
    "                   genetypes='gencode'):\n",
    "\n",
    "    params_library = {'query':input_snps,\n",
    "                      'gwas_id':0,\n",
    "                      'ldThresh': r2_threshold,\n",
    "                      'ldPop': ldPop,\n",
    "                      'epi': epi,\n",
    "                      'cons': cons,\n",
    "                      'genetypes': genetypes,\n",
    "                      'output':'text'}\n",
    "    \n",
    "    # parameters passed to the website, needs to be parsed and in binary\n",
    "    params = urllib.parse.urlencode(params_library).encode(\"utf-8\")\n",
    "    # url of HaploReg4.1\n",
    "    url = 'https://pubs.broadinstitute.org/mammals/haploreg/haploreg.php'\n",
    "    # Query with parameters\n",
    "    query = urllib.request.urlopen(url, params)\n",
    "    content = query.read().decode(\"utf-8\")\n",
    "    # Write returned result in a remove_snps.txt file, those are SNPs to be removed\n",
    "    open('remove_snps.txt', 'w').write(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# The tricky part for me is to query haploreg database thorugh their website.\n",
    "# Inspecct the element of the website to find out names of each variable\n",
    "# Recommand using Chrome, go to developer mode, refresh the website under Network tab\n",
    "\n",
    "# Parameters needed to send to haploreg website, and some explaination\n",
    "# input_snps (query): input SNPs in a string, each SNP is separated by ','\n",
    "#        SNP number per query is set to be 1000, otherwise it takes too long and haploreg may refuse to do it.\n",
    "#        15000 SNPs did not work for test run.\n",
    "# gwas_id: the dropdown list to choose GWAS study, when no file or query SNP(s) is provided\n",
    "# r2_threshold (ldThresh): r^2 threshold, default is 0.2 in this code\n",
    "# ldPop: 1000G Phase 1 population for LD calculation\n",
    "# epi: Source for epigenomes\n",
    "# cons: Mammalian conservation algorithm. 'siphy'=SiPhy-omega, 'gerp'=GERP, or 'both'\n",
    "# genetypes: Show position relative to\n",
    "# output: set output result type to 'text' for python code to process\n",
    "\n",
    "# This function is the same as above, but is intended to query one SNP at a time\n",
    "def single_query_haploreg(input_snp,\n",
    "                   r2_threshold=0.8,\n",
    "                   ldPop='EUR',\n",
    "                   epi='vanilla',\n",
    "                   cons='siphy',\n",
    "                   genetypes='gencode'):\n",
    "\n",
    "    params_library = {'query':input_snp,\n",
    "                      'gwas_id':0,\n",
    "                      'ldThresh': r2_threshold,\n",
    "                      'ldPop': ldPop,\n",
    "                      'epi': epi,\n",
    "                      'cons': cons,\n",
    "                      'genetypes': genetypes,\n",
    "                      'output':'text'}\n",
    "    \n",
    "    # parameters passed to the website, needs to be parsed and in binary\n",
    "    params = urllib.parse.urlencode(params_library).encode(\"utf-8\")\n",
    "    # url of HaploReg4.1\n",
    "    url = 'https://pubs.broadinstitute.org/mammals/haploreg/haploreg.php'\n",
    "    # Query with parameters\n",
    "    query = urllib.request.urlopen(url, params)\n",
    "    content = query.read().decode(\"utf-8\")\n",
    "    # Find accociated SNPs in the content returned from HaploReg\n",
    "    matches = re.findall('rs[0-9]+', content)\n",
    "    \n",
    "    # Queried rsID will always be returned, so it needs to be removed\n",
    "    # Matches contains rsIDs to be removed\n",
    "    index = 0\n",
    "    while index<len(matches):\n",
    "        if matches[index] == single_snp:\n",
    "            matches.remove(single_snp)\n",
    "            index = index-1 # Need to reduce index by one, otherwise will not check all elements\n",
    "        index = index+1\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "['rs4790914', 'rs4791079', 'rs1971682', 'rs4366742', 'rs2215415', 'rs2215414', 'rs3744317', 'rs8178845', 'rs8178827', 'rs71160546', 'rs10048158', 'rs9895261', 'rs12603947', 'rs7342920']\n"
     ]
    }
   ],
   "source": [
    "# single_snp = 'rs10048158'\n",
    "single_snp = 'rs4791078'\n",
    "remove_SNPs = single_query_haploreg(single_snp)\n",
    "print(len(remove_SNPs))\n",
    "print(remove_SNPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-455680ca2399>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-455680ca2399>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
