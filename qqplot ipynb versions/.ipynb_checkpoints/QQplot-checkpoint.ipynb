{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib\n",
    "\n",
    "# Read a .txt or .csv file containing SNPs and P values to be plotted\n",
    "# Function checks delimiters automatically\n",
    "# Parameter: filename - .txt or .csv file containing information needed\n",
    "# Return: pandas dataframe of the file\n",
    "def __read_file(filename):\n",
    "    fh = open(filename, 'r')\n",
    "    line = fh.readline()\n",
    "    tmp = line.strip().split(',')\n",
    "\n",
    "    # Create an empty dataframe, read data into df later\n",
    "    df = pd.DataFrame()\n",
    "    # Check delimiter type, \",\" or \" \"\n",
    "    if len(tmp) == 1:\n",
    "        df = pd.read_csv(filename, delim_whitespace=True)\n",
    "    else:\n",
    "        df = pd.read_csv(filename)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "# Return -log10 transformed observed and expected p vlaues of a dataset(dataframe)\n",
    "def __log_obsv_and_expt(df, column_title):\n",
    "    Pobsv = df.loc[:, column_title]  # Observed p values\n",
    "    Pobsv = np.sort(Pobsv.dropna().values)\n",
    "    Pexpt = np.arange(1, len(Pobsv) + 1, 1) / (len(Pobsv) + 1)  # Expected\n",
    "    logPobsv = -np.log10(Pobsv)\n",
    "    logPexpt = -np.log10(Pexpt)\n",
    "    \n",
    "    return(Pobsv, logPobsv, logPexpt)\n",
    "\n",
    "\n",
    "# Calculate and return lambda (inflation)\n",
    "def __get_inflation__(observed):\n",
    "    obsv_median = np.median(observed)\n",
    "    Chi = chi2.ppf(1.0 - obsv_median, 1)\n",
    "    lmbd = Chi / chi2.ppf(0.5, 1)\n",
    "    return lmbd\n",
    "\n",
    "\n",
    "# The tricky part for me is to query haploreg database thorugh their website.\n",
    "# Inspecct the element of the website to find out names of each variable\n",
    "# Recommand using Chrome, go to developer mode, refresh the website under Network tab\n",
    "# This function is intended to query one SNP at a time\n",
    "# Return: a set of rsIDs of accociated SNPs (and the queried SNP)\n",
    "\n",
    "# Parameters needed to send to haploreg website, and some explaination\n",
    "# input_snps (query): input SNPs in a string, each SNP is separated by ','\n",
    "#        SNP number per query is set to be 1000, otherwise it takes too long and haploreg may refuse to do it.\n",
    "#        15000 SNPs did not work for test run.\n",
    "# gwas_id: the dropdown list to choose GWAS study, when no file or query SNP(s) is provided\n",
    "# r2_threshold (ldThresh): r^2 threshold, default is 0.2 in this code\n",
    "# ldPop: 1000G Phase 1 population for LD calculation\n",
    "# epi: Source for epigenomes\n",
    "# cons: Mammalian conservation algorithm. 'siphy'=SiPhy-omega, 'gerp'=GERP, or 'both'\n",
    "# genetypes: Show position relative to\n",
    "# output: set output result type to 'text' for python code to process\n",
    "def single_query_haploreg(input_snp,\n",
    "                   r2_threshold=0.2,\n",
    "                   ldPop='EUR',\n",
    "                   epi='vanilla',\n",
    "                   cons='siphy',\n",
    "                   genetypes='gencode'):\n",
    "\n",
    "    params_library = {'query':input_snp,\n",
    "                      'gwas_id':0,\n",
    "                      'ldThresh': r2_threshold,\n",
    "                      'ldPop': ldPop,\n",
    "                      'epi': epi,\n",
    "                      'cons': cons,\n",
    "                      'genetypes': genetypes,\n",
    "                      'output':'text'}\n",
    "    \n",
    "    # parameters passed to the website, needs to be parsed and in binary\n",
    "    params = urllib.parse.urlencode(params_library).encode(\"utf-8\")\n",
    "    # url of HaploReg4.1\n",
    "    url = 'https://pubs.broadinstitute.org/mammals/haploreg/haploreg.php'\n",
    "    # Query with parameters\n",
    "    query = urllib.request.urlopen(url, params)\n",
    "    content = query.read().decode(\"utf-8\")\n",
    "    # Find accociated SNPs in the content returned from HaploReg\n",
    "    matches = re.findall('rs[0-9]+', content)\n",
    "\n",
    "    # Return unique ones of the query\n",
    "    return(set(matches))\n",
    "#     return content\n",
    "\n",
    "\n",
    "# Queried SNPs are based on the file provided\n",
    "# Parameter:\n",
    "# - \n",
    "# -\n",
    "# Return: Save novel SNPs as .csv file fot plotting and reference\n",
    "def __novel_SNPs(filename, r2_threshold, SNPs_column_title, novel_filename='novel_SNPs.csv'):\n",
    "    original_df = __read_file(filename) # Dataframe read from the file\n",
    "    all_SNPs = original_df.loc[:, SNPs_column_title].values # Get all SNPs in the file to be queried\n",
    "    associated_SNPs = np.array([]) # A numpy array to store queried results\n",
    "    \n",
    "    # Count is to show numbers of SNPs processed so far, to keep the console updating\n",
    "    count = 0\n",
    "    for snp in all_SNPs:\n",
    "        associated_SNPs = np.append(associated_SNPs, single_query_haploreg(input_snp=snp, r2_threshold=r2_threshold))\n",
    "        \n",
    "        count = count+1\n",
    "        # Print every 10 SNPs\n",
    "        if count%10 == 0:\n",
    "            print('Number of SNPs processed: ' + str(count))\n",
    "        \n",
    "    \n",
    "    # Remove duplicates of queried results\n",
    "    associated_SNPs = np.unique(associated_SNPs)\n",
    "    \n",
    "    # Join the original dataframe and queried results, output novel SNPs\n",
    "    original_df.set_index(SNPs_column_title, inplace=True)\n",
    "    associated_df = pd.DataFrame([], index=associated_SNPs)\n",
    "    remove_df = original_df.join(associated_df, how='inner')\n",
    "    novel_df = original_df.drop(remove_df.index.values)\n",
    "    \n",
    "    novel_df.to_csv(novel_filename)\n",
    "\n",
    "# Returns: (fig, ax, lambda)\n",
    "# fig and ax for more custermizations\n",
    "def qqplot(filename,\n",
    "           output='output.png',\n",
    "           column_title = 'P',\n",
    "           title='Q-Q plot',\n",
    "           xlabel='Expected –log10 P-values',\n",
    "           ylabel='Observed –log10 P-values',\n",
    "           dpi=300,\n",
    "           plot_novel = False,\n",
    "           novel_filename = 'novel_SNPs.csv',\n",
    "           SNPs_column_title = 'SNP',\n",
    "           r2_threshold=0.2):\n",
    "    \n",
    "    df = __read_file(filename)\n",
    "    \n",
    "#     Pobsv = df.loc[:, column_title]  # Observed p values\n",
    "#     Pobsv = np.sort(Pobsv.dropna().values)\n",
    "#     Pexpt = np.arange(1, len(Pobsv) + 1, 1) / (len(Pobsv) + 1)  # Expected\n",
    "#     logPobsv = -np.log10(Pobsv)\n",
    "#     logPexpt = -np.log10(Pexpt)\n",
    "\n",
    "    Pobsv, logPobsv, logPexpt = __log_obsv_and_expt(df, column_title)\n",
    "\n",
    "    # Calculate lambda\n",
    "    infl = __get_inflation__(Pobsv)\n",
    "\n",
    "    fig, ax = plt.subplots(dpi=dpi)\n",
    "    ax.plot(logPexpt, logPobsv, linestyle='', marker='o', markersize=3, markeredgewidth=0.5,\n",
    "            fillstyle='none', color='k', alpha=0.8)\n",
    "    ax.plot(logPexpt, logPexpt, color='r', linewidth=0.4)\n",
    "\n",
    "    # Label x and y axis\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    annotation = \"λ = \" + str(\"{0:.4f}\".format(infl))\n",
    "    ax.annotate(annotation, xy=(0.7, 0.2), xycoords='axes fraction')\n",
    "    \n",
    "    if plot_novel == True:\n",
    "        # Plot novel SNPs, then same steps as before\n",
    "        __novel_SNPs(filename, r2_threshold, SNPs_column_title, novel_filename)\n",
    "        novel_SNPs_df = __read_file(novel_filename)\n",
    "        \n",
    "#         Pobsv_novel = novel_SNPs_df.loc[:, column_title]  # Observed p values\n",
    "#         Pobsv_novel = np.sort(Pobsv_novel.dropna().values)\n",
    "#         Pexpt_novel = np.arange(1, len(Pobsv_novel) + 1, 1) / (len(Pobsv_novel) + 1)  # Expected\n",
    "#         logPobsv_novel = -np.log10(Pobsv_novel)\n",
    "#         logPexpt_novel = -np.log10(Pexpt_novel)\n",
    "        Pobsv_novel, logPobsv_novel, logPexpt_novel = __log_obsv_and_expt(novel_SNPs_df, column_title)\n",
    "\n",
    "        ax.plot(logPexpt_novel, logPobsv_novel, linestyle='', marker='o', markersize=3, markeredgewidth=0.5,\n",
    "                fillstyle='none', color='g', alpha=0.8)\n",
    "    \n",
    "    fig.savefig(output)\n",
    "    \n",
    "    return (fig, ax, infl)  # Return for more custermizations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a df and scan for novel SNPs\n",
    "# Better to process about 100 SNPs at a time, so the process will not take too long.\n",
    "# column_title is the titile of the column that contains rsIDs\n",
    "# Output the reuslt into a .csv file\n",
    "def __associated_SNPs(file_df, column_title='SNP', r2_threshold=0.2, output='associated_SNPs.txt'):\n",
    "    all_SNPs = file_df.loc[:,column_title].values # Get all SNPs in the file to be queried\n",
    "    associated_SNPs = set() # A numpy array to store queried results\n",
    "\n",
    "    for snp in all_SNPs:\n",
    "        associated_SNPs = np.append(associated_SNPs, single_query_haploreg(input_snp=snp, r2_threshold=r2_threshold))\n",
    "    \n",
    "    # Remove duplicates of queried results\n",
    "    associated_SNPs = np.unique(associated_SNPs)\n",
    "    np.savetxt(output, associated_SNPs, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be single or multiple SNP queris (each rsID is separated by ',')\n",
    "def query_haploreg(input_snp,\n",
    "                   r2_threshold=0.2,\n",
    "                   ldPop='EUR',\n",
    "                   epi='vanilla',\n",
    "                   cons='siphy',\n",
    "                   genetypes='gencode'):\n",
    "\n",
    "    params_library = {'query':input_snp,\n",
    "                      'gwas_id':0,\n",
    "                      'ldThresh': r2_threshold,\n",
    "                      'ldPop': ldPop,\n",
    "                      'epi': epi,\n",
    "                      'cons': cons,\n",
    "                      'genetypes': genetypes,\n",
    "                      'output':'text'}\n",
    "    \n",
    "    # parameters passed to the website, needs to be parsed and in binary\n",
    "    params = urllib.parse.urlencode(params_library).encode(\"utf-8\")\n",
    "    # url of HaploReg4.1\n",
    "    url = 'https://pubs.broadinstitute.org/mammals/haploreg/haploreg.php'\n",
    "    # Query with parameters\n",
    "    query = urllib.request.urlopen(url, params)\n",
    "    content = query.read().decode(\"utf-8\")\n",
    "    # Find accociated SNPs in the content returned from HaploReg\n",
    "    matches = re.findall('rs[0-9]+', content)\n",
    "\n",
    "    # Return unique ones of the query\n",
    "    return(list(set(matches)))\n",
    "\n",
    "# This function returns known SNPs (and associated SNPs) based on user input file\n",
    "# Parameters:\n",
    "#  - filename: a file contains known SNPs, provided by user\n",
    "#  - r2_threshold: LD threshold, defualt is 0.2\n",
    "#  - SNPs_column_title: Column title of SNPs in that file\n",
    "# Return: a list of associated SNPs pulled from HaploReg and known SNPs provided by user\n",
    "def __known_SNPs(filename, r2_threshold=0.2, SNPs_column_title='SNP'):\n",
    "    known_SNPs_df = __read_file(filename) # Dataframe of known SNPs\n",
    "    # Get all SNPs to be queried, join them by ',' and query together\n",
    "    known_SNPs = ','.join(known_SNPs_df.loc[:, SNPs_column_title].values)\n",
    "    # A numpy array to store queried results\n",
    "    associated_and_known_SNPs = query_haploreg(input_snp=known_SNPs, r2_threshold=r2_threshold)\n",
    "    \n",
    "#     if len(known_SNPs_df)>100:\n",
    "\n",
    "\n",
    "    # Remove duplicates of queried results and return\n",
    "    return(set(associated_and_known_SNPs))\n",
    "\n",
    "# This function removes known SNPs and save novel SNPs in a .csv file\n",
    "# Parameters:\n",
    "#  - original_df: a dataframe containing raw data of SNPs and p values\n",
    "#  - known_SNPs: a list of SNPs found in other GWAS, that are associated with traits of interest\n",
    "#  - SNPs_column_title: Column title of SNPs in that file\n",
    "# Return: a datafram of novel SNPs and p values\n",
    "def __remove_known_SNPs(original_df, known_SNPs, SNPs_column_title='SNP', novel_filename='novel_SNPs'):\n",
    "    # Join the original dataframe and konw SNPs, output novel SNPs to be plotted\n",
    "    original_df.set_index(SNPs_column_title, inplace=True)\n",
    "    known_SNPs_df = pd.DataFrame([], index=known_SNPs)\n",
    "    to_be_removed_SNPs_df = original_df.join(known_SNPs_df, how='inner')\n",
    "    novel_df = original_df.drop(to_be_removed_SNPs_df.index.values)\n",
    "    \n",
    "    novel_df.to_csv(novel_filename)\n",
    "    return(novel_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = 'Data/DLD_GWAS_10.csv'\n",
    "a = __known_SNPs(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = __read_file('Data/ADD_only_DLD_GWAS.txt')\n",
    "new_df = __remove_known_SNPs(original_df, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "gwas_filename_01 = \"/data100t1/share/DIAMANTE/mrmega_hdl_final_0619_rsids_locuszoom.result\"\n",
    "gwas_filename_02 = \"/data100t1/share/DIAMANTE/mrmega_hdl_final_0619_rsids.result\"\n",
    "\n",
    "gwas_df = pd.read_csv(gwas_filename_02, sep='\\t')\n",
    "\n",
    "# fh = open(gwas_filename_02, 'r')\n",
    "# count=0\n",
    "# for line in fh:\n",
    "#     print(line.strip().split('\\t'))\n",
    "#     count=count+1\n",
    "#     if count>10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MarkerName</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>Position</th>\n",
       "      <th>EA</th>\n",
       "      <th>NEA</th>\n",
       "      <th>EAF</th>\n",
       "      <th>Nsample</th>\n",
       "      <th>Ncohort</th>\n",
       "      <th>Effects</th>\n",
       "      <th>beta_0</th>\n",
       "      <th>...</th>\n",
       "      <th>ndf_association</th>\n",
       "      <th>P-value_association</th>\n",
       "      <th>chisq_ancestry_het</th>\n",
       "      <th>ndf_ancestry_het</th>\n",
       "      <th>P-value_ancestry_het</th>\n",
       "      <th>chisq_residual_het</th>\n",
       "      <th>ndf_residual_het</th>\n",
       "      <th>P-value_residual_het</th>\n",
       "      <th>lnBF</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rs147324274</td>\n",
       "      <td>10</td>\n",
       "      <td>100000012</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>26037</td>\n",
       "      <td>4</td>\n",
       "      <td>-?????????+??????++</td>\n",
       "      <td>-1.252750</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.317464</td>\n",
       "      <td>0.677718</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.410374</td>\n",
       "      <td>0.223172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.894415</td>\n",
       "      <td>-0.238903</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs144804129</td>\n",
       "      <td>10</td>\n",
       "      <td>100000122</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>0.997312</td>\n",
       "      <td>27449</td>\n",
       "      <td>6</td>\n",
       "      <td>-+?????+??+??????+-</td>\n",
       "      <td>0.086105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.765692</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.979314</td>\n",
       "      <td>3.196730</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.525459</td>\n",
       "      <td>-1.524780</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs6602381</td>\n",
       "      <td>10</td>\n",
       "      <td>10000018</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>0.541823</td>\n",
       "      <td>38176</td>\n",
       "      <td>19</td>\n",
       "      <td>+++--+-++-+-+--++++</td>\n",
       "      <td>0.029652</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.295628</td>\n",
       "      <td>0.875949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.349314</td>\n",
       "      <td>12.777500</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.750949</td>\n",
       "      <td>-1.725790</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rs189891329</td>\n",
       "      <td>10</td>\n",
       "      <td>10000033</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0.994151</td>\n",
       "      <td>26037</td>\n",
       "      <td>4</td>\n",
       "      <td>-?????????+??????+-</td>\n",
       "      <td>-1.370290</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.475657</td>\n",
       "      <td>1.028940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.310409</td>\n",
       "      <td>7.119850</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.028441</td>\n",
       "      <td>-0.643236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rs112832083</td>\n",
       "      <td>10</td>\n",
       "      <td>100000588</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>0.992032</td>\n",
       "      <td>28518</td>\n",
       "      <td>7</td>\n",
       "      <td>+??-?+?+??+??????+-</td>\n",
       "      <td>-0.237271</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.093044</td>\n",
       "      <td>1.776260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.182610</td>\n",
       "      <td>2.751990</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.738157</td>\n",
       "      <td>0.428771</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MarkerName  Chromosome   Position EA NEA       EAF  Nsample  Ncohort  \\\n",
       "0  rs147324274          10  100000012  G   A  0.996606    26037        4   \n",
       "1  rs144804129          10  100000122  T   A  0.997312    27449        6   \n",
       "2    rs6602381          10   10000018  A   G  0.541823    38176       19   \n",
       "3  rs189891329          10   10000033  G   A  0.994151    26037        4   \n",
       "4  rs112832083          10  100000588  T   C  0.992032    28518        7   \n",
       "\n",
       "               Effects    beta_0  ...  ndf_association  P-value_association  \\\n",
       "0  -?????????+??????++ -1.252750  ...              2.0             0.317464   \n",
       "1  -+?????+??+??????+-  0.086105  ...              2.0             0.765692   \n",
       "2  +++--+-++-+-+--++++  0.029652  ...              2.0             0.295628   \n",
       "3  -?????????+??????+- -1.370290  ...              2.0             0.475657   \n",
       "4  +??-?+?+??+??????+- -0.237271  ...              2.0             0.093044   \n",
       "\n",
       "   chisq_ancestry_het  ndf_ancestry_het  P-value_ancestry_het  \\\n",
       "0            0.677718               1.0              0.410374   \n",
       "1            0.000672               1.0              0.979314   \n",
       "2            0.875949               1.0              0.349314   \n",
       "3            1.028940               1.0              0.310409   \n",
       "4            1.776260               1.0              0.182610   \n",
       "\n",
       "   chisq_residual_het  ndf_residual_het  P-value_residual_het      lnBF  \\\n",
       "0            0.223172               2.0              0.894415 -0.238903   \n",
       "1            3.196730               4.0              0.525459 -1.524780   \n",
       "2           12.777500              17.0              0.750949 -1.725790   \n",
       "3            7.119850               2.0              0.028441 -0.643236   \n",
       "4            2.751990               5.0              0.738157  0.428771   \n",
       "\n",
       "   Comments  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gwas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33512268"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gwas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33783872"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gwas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1800x1200 with 1 Axes>,\n",
       " <matplotlib.axes._subplots.AxesSubplot at 0x7fc6383c5cf8>,\n",
       " 1.0720526881638353)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qqplot(filename=gwas_filename_01,output='20190930_mrmega_hdl.png',\n",
    "       column_title = 'P-value_association',title='mrmega_hdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_01 = '/data100t1/share/DIAMANTE/GWAS_catalog_results_HDL.txt'\n",
    "novel_df = pd.read_csv(novel_01, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE ADDED TO CATALOG</th>\n",
       "      <th>PUBMEDID</th>\n",
       "      <th>FIRST AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>JOURNAL</th>\n",
       "      <th>LINK</th>\n",
       "      <th>STUDY</th>\n",
       "      <th>DISEASE/TRAIT</th>\n",
       "      <th>INITIAL SAMPLE SIZE</th>\n",
       "      <th>REPLICATION SAMPLE SIZE</th>\n",
       "      <th>...</th>\n",
       "      <th>PVALUE_MLOG</th>\n",
       "      <th>P-VALUE (TEXT)</th>\n",
       "      <th>OR or BETA</th>\n",
       "      <th>95% CI (TEXT)</th>\n",
       "      <th>PLATFORM [SNPS PASSING QC]</th>\n",
       "      <th>CNV</th>\n",
       "      <th>MAPPED_TRAIT</th>\n",
       "      <th>MAPPED_TRAIT_URI</th>\n",
       "      <th>STUDY ACCESSION</th>\n",
       "      <th>GENOTYPING TECHNOLOGY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/21/17</td>\n",
       "      <td>28270201</td>\n",
       "      <td>Nagy R</td>\n",
       "      <td>3/7/17</td>\n",
       "      <td>Genome Med</td>\n",
       "      <td>www.ncbi.nlm.nih.gov/pubmed/28270201</td>\n",
       "      <td>Exploration of haplotype research consortium i...</td>\n",
       "      <td>HDL cholesterol</td>\n",
       "      <td>19,223 British ancestry individuals from 6863 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.522879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.867736</td>\n",
       "      <td>[0.56-1.18] mg/dl increase</td>\n",
       "      <td>Illumina [24111857] (imputed)</td>\n",
       "      <td>N</td>\n",
       "      <td>high density lipoprotein cholesterol measurement</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0004612</td>\n",
       "      <td>GCST004207</td>\n",
       "      <td>Genome-wide genotyping array</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/14/19</td>\n",
       "      <td>29507422</td>\n",
       "      <td>Hoffmann TJ</td>\n",
       "      <td>3/5/18</td>\n",
       "      <td>Nat Genet</td>\n",
       "      <td>www.ncbi.nlm.nih.gov/pubmed/29507422</td>\n",
       "      <td>A large electronic-health-record-based genome-...</td>\n",
       "      <td>High density lipoprotein cholesterol levels</td>\n",
       "      <td>76,627 European ancestry individuals, 7,795 Hi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.698970</td>\n",
       "      <td>(EA)</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>unit increase</td>\n",
       "      <td>Affymetrix [at least 7091467] (imputed)</td>\n",
       "      <td>N</td>\n",
       "      <td>high density lipoprotein cholesterol measurement</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0004612</td>\n",
       "      <td>GCST007140</td>\n",
       "      <td>Genome-wide genotyping array</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/14/19</td>\n",
       "      <td>29507422</td>\n",
       "      <td>Hoffmann TJ</td>\n",
       "      <td>3/5/18</td>\n",
       "      <td>Nat Genet</td>\n",
       "      <td>www.ncbi.nlm.nih.gov/pubmed/29507422</td>\n",
       "      <td>A large electronic-health-record-based genome-...</td>\n",
       "      <td>High density lipoprotein cholesterol levels</td>\n",
       "      <td>76,627 European ancestry individuals, 7,795 Hi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>13.698970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>unit increase</td>\n",
       "      <td>Affymetrix [at least 7091467] (imputed)</td>\n",
       "      <td>N</td>\n",
       "      <td>high density lipoprotein cholesterol measurement</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0004612</td>\n",
       "      <td>GCST007140</td>\n",
       "      <td>Genome-wide genotyping array</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/12/14</td>\n",
       "      <td>24097068</td>\n",
       "      <td>Willer CJ</td>\n",
       "      <td>10/6/13</td>\n",
       "      <td>Nat Genet</td>\n",
       "      <td>www.ncbi.nlm.nih.gov/pubmed/24097068</td>\n",
       "      <td>Discovery and refinement of loci associated wi...</td>\n",
       "      <td>HDL cholesterol</td>\n",
       "      <td>94,595 European ancestry individuals</td>\n",
       "      <td>93,982 European ancestry individuals</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>[NR] unit decrease</td>\n",
       "      <td>NR [NR] (imputed)</td>\n",
       "      <td>N</td>\n",
       "      <td>high density lipoprotein cholesterol measurement</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0004612</td>\n",
       "      <td>GCST002223</td>\n",
       "      <td>Genome-wide genotyping array</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/26/17</td>\n",
       "      <td>28334899</td>\n",
       "      <td>Spracklen CN</td>\n",
       "      <td>2/21/17</td>\n",
       "      <td>Hum Mol Genet</td>\n",
       "      <td>www.ncbi.nlm.nih.gov/pubmed/28334899</td>\n",
       "      <td>Association analyses of East Asian individuals...</td>\n",
       "      <td>HDL cholesterol levels</td>\n",
       "      <td>34,930 East Asian ancestry individuals, 187,16...</td>\n",
       "      <td>8,741 Chinese ancestry individuals</td>\n",
       "      <td>...</td>\n",
       "      <td>15.045757</td>\n",
       "      <td>(Trans-ethnic initial)</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>[0.038-0.063] unit decrease (EA Beta values)</td>\n",
       "      <td>Affymetrix, Illumina [~ 1900000] (imputed)</td>\n",
       "      <td>N</td>\n",
       "      <td>high density lipoprotein cholesterol measurement</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0004612</td>\n",
       "      <td>GCST004232</td>\n",
       "      <td>Genome-wide genotyping array</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  DATE ADDED TO CATALOG  PUBMEDID  FIRST AUTHOR     DATE        JOURNAL  \\\n",
       "0               6/21/17  28270201        Nagy R   3/7/17     Genome Med   \n",
       "1               2/14/19  29507422   Hoffmann TJ   3/5/18      Nat Genet   \n",
       "2               2/14/19  29507422   Hoffmann TJ   3/5/18      Nat Genet   \n",
       "3               5/12/14  24097068     Willer CJ  10/6/13      Nat Genet   \n",
       "4               6/26/17  28334899  Spracklen CN  2/21/17  Hum Mol Genet   \n",
       "\n",
       "                                   LINK  \\\n",
       "0  www.ncbi.nlm.nih.gov/pubmed/28270201   \n",
       "1  www.ncbi.nlm.nih.gov/pubmed/29507422   \n",
       "2  www.ncbi.nlm.nih.gov/pubmed/29507422   \n",
       "3  www.ncbi.nlm.nih.gov/pubmed/24097068   \n",
       "4  www.ncbi.nlm.nih.gov/pubmed/28334899   \n",
       "\n",
       "                                               STUDY  \\\n",
       "0  Exploration of haplotype research consortium i...   \n",
       "1  A large electronic-health-record-based genome-...   \n",
       "2  A large electronic-health-record-based genome-...   \n",
       "3  Discovery and refinement of loci associated wi...   \n",
       "4  Association analyses of East Asian individuals...   \n",
       "\n",
       "                                 DISEASE/TRAIT  \\\n",
       "0                              HDL cholesterol   \n",
       "1  High density lipoprotein cholesterol levels   \n",
       "2  High density lipoprotein cholesterol levels   \n",
       "3                              HDL cholesterol   \n",
       "4                       HDL cholesterol levels   \n",
       "\n",
       "                                 INITIAL SAMPLE SIZE  \\\n",
       "0  19,223 British ancestry individuals from 6863 ...   \n",
       "1  76,627 European ancestry individuals, 7,795 Hi...   \n",
       "2  76,627 European ancestry individuals, 7,795 Hi...   \n",
       "3               94,595 European ancestry individuals   \n",
       "4  34,930 East Asian ancestry individuals, 187,16...   \n",
       "\n",
       "                REPLICATION SAMPLE SIZE  ... PVALUE_MLOG  \\\n",
       "0                                   NaN  ...    7.522879   \n",
       "1                                   NaN  ...   13.698970   \n",
       "2                                   NaN  ...   13.698970   \n",
       "3  93,982 European ancestry individuals  ...   15.000000   \n",
       "4    8,741 Chinese ancestry individuals  ...   15.045757   \n",
       "\n",
       "           P-VALUE (TEXT) OR or BETA  \\\n",
       "0                     NaN   0.867736   \n",
       "1                    (EA)   0.113000   \n",
       "2                     NaN   0.114000   \n",
       "3                     NaN   0.051000   \n",
       "4  (Trans-ethnic initial)   0.050600   \n",
       "\n",
       "                                  95% CI (TEXT)  \\\n",
       "0                    [0.56-1.18] mg/dl increase   \n",
       "1                                 unit increase   \n",
       "2                                 unit increase   \n",
       "3                            [NR] unit decrease   \n",
       "4  [0.038-0.063] unit decrease (EA Beta values)   \n",
       "\n",
       "                   PLATFORM [SNPS PASSING QC] CNV  \\\n",
       "0               Illumina [24111857] (imputed)   N   \n",
       "1     Affymetrix [at least 7091467] (imputed)   N   \n",
       "2     Affymetrix [at least 7091467] (imputed)   N   \n",
       "3                           NR [NR] (imputed)   N   \n",
       "4  Affymetrix, Illumina [~ 1900000] (imputed)   N   \n",
       "\n",
       "                                       MAPPED_TRAIT  \\\n",
       "0  high density lipoprotein cholesterol measurement   \n",
       "1  high density lipoprotein cholesterol measurement   \n",
       "2  high density lipoprotein cholesterol measurement   \n",
       "3  high density lipoprotein cholesterol measurement   \n",
       "4  high density lipoprotein cholesterol measurement   \n",
       "\n",
       "                       MAPPED_TRAIT_URI  STUDY ACCESSION  \\\n",
       "0  http://www.ebi.ac.uk/efo/EFO_0004612       GCST004207   \n",
       "1  http://www.ebi.ac.uk/efo/EFO_0004612       GCST007140   \n",
       "2  http://www.ebi.ac.uk/efo/EFO_0004612       GCST007140   \n",
       "3  http://www.ebi.ac.uk/efo/EFO_0004612       GCST002223   \n",
       "4  http://www.ebi.ac.uk/efo/EFO_0004612       GCST004232   \n",
       "\n",
       "          GENOTYPING TECHNOLOGY  \n",
       "0  Genome-wide genotyping array  \n",
       "1  Genome-wide genotyping array  \n",
       "2  Genome-wide genotyping array  \n",
       "3  Genome-wide genotyping array  \n",
       "4  Genome-wide genotyping array  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(novel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot do slice indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [5] of <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-68a6db65b9e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnovel_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data100t1/gapps/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1492\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data100t1/gapps/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    886\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data100t1/gapps/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data100t1/gapps/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m         indexer = labels.slice_indexer(slice_obj.start, slice_obj.stop,\n\u001b[0;32m-> 1533\u001b[0;31m                                        slice_obj.step, kind=self.name)\n\u001b[0m\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data100t1/gapps/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   4671\u001b[0m         \"\"\"\n\u001b[1;32m   4672\u001b[0m         start_slice, end_slice = self.slice_locs(start, end, step=step,\n\u001b[0;32m-> 4673\u001b[0;31m                                                  kind=kind)\n\u001b[0m\u001b[1;32m   4674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4675\u001b[0m         \u001b[0;31m# return a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data100t1/gapps/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   4870\u001b[0m         \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4872\u001b[0;31m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_slice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4874\u001b[0m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data100t1/gapps/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   4796\u001b[0m         \u001b[0;31m# For datetime indices label may be a string that has to be converted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4797\u001b[0m         \u001b[0;31m# to datetime boundary according to its resolution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4798\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4800\u001b[0m         \u001b[0;31m# we need to look up the label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data100t1/gapps/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_maybe_cast_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   4748\u001b[0m         \u001b[0;31m# this is rejected (generally .loc gets you here)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4749\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4750\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalid_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'slice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data100t1/gapps/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_invalid_indexer\u001b[0;34m(self, form, key)\u001b[0m\n\u001b[1;32m   3065\u001b[0m                         \"indexers [{key}] of {kind}\".format(\n\u001b[1;32m   3066\u001b[0m                             \u001b[0mform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3067\u001b[0;31m                             kind=type(key)))\n\u001b[0m\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3069\u001b[0m     \u001b[0;31m# --------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot do slice indexing on <class 'pandas.core.indexes.base.Index'> with these indexers [5] of <class 'int'>"
     ]
    }
   ],
   "source": [
    "novel_df.loc[:10,5: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
